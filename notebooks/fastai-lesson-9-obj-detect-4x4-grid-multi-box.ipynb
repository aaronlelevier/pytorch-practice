{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json\nimport os\nfrom pathlib import Path\nimport time\nimport copy\nimport datetime\nimport collections\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nfrom fastai.dataset import open_image\nimport json\nfrom PIL import ImageDraw, ImageFont\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches, patheffects\nimport cv2\nfrom tqdm import tqdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "118bf972c981d93118fe3b203b95d9094b85643e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# params\nSIZE = 224\nEPOCHS = 5\nBATCH_SIZE = 32\nNUM_WORKERS = 4\nSHOW_IMAGES = False\n\n# static\nIMAGES = 'images'\nANNOTATIONS = 'annotations'\nCATEGORIES = 'categories'\nID = 'id'\nNAME = 'name'\nIMAGE_ID = 'image_id'\nBBOX = 'bbox'\nCATEGORY_ID = 'category_id'\nFILE_NAME = 'file_name'\nIMAGE = 'image'\nCATEGORY = 'category'\nTRAIN = 'train'\nVAL = 'val'\nTEST = 'test'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1c3cbd58f17c3d2bec6fa63d3466b5174ae36066",
        "trusted": true
      },
      "cell_type": "code",
      "source": "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice = 'cpu'\nprint('device:', device)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "734c33e32f7ebd091b5c26a2d4e72661d364e6e7"
      },
      "cell_type": "markdown",
      "source": "Adjust data dir path for Paperspace or Kaggle"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8c6a0460814f93fd64df21fc1348736b891ed1c2"
      },
      "cell_type": "code",
      "source": "home_dir = os.path.expanduser('~')\n\nif home_dir == '/home/paperspace':\n    DATA_DIR = '/home/paperspace/data/pascal'\nelse: # kaggle\n    DATA_DIR = '../input/pascal/pascal'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3f0c759a56e66938c6739e49811c39275f5e1d3c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "PATH = Path(DATA_DIR)\nlist(PATH.iterdir())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "73c706f2cf75e5859ba28933ca3cb5b6ca21d9a8",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_data = json.load((PATH/'pascal_train2007.json').open())\nval_data = json.load((PATH/'pascal_val2007.json').open())\ntest_data = json.load((PATH/'pascal_test2007.json').open())\n\nprint('train:', train_data.keys())\nprint('val:', val_data.keys())\nprint('test:', test_data.keys())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b64e18e88771a9b047ed542a7a98466ddcab8d35"
      },
      "cell_type": "code",
      "source": "def preview_data(data):\n    if isinstance(data, (list, tuple)):\n        return data[0]\n    elif isinstance(data, dict):\n        return next(iter(data.items()))\n    else:\n        raise TypeError(f\"Unsupported type: {type(data)}\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7896f1a629da6bfeb585749ff21a5a2e59ba0886"
      },
      "cell_type": "code",
      "source": "train_data.keys()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ef583f5efd5e4adf8093ca1f3dcf96febc4a2adf",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "preview_data(train_data[ANNOTATIONS])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9a314f39827bd1e068ee355679491feb828137f1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "preview_data(train_data[IMAGES])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f4a3cdc3f414c19e16cf66aabdbd43aca7fc3fda",
        "trusted": true
      },
      "cell_type": "code",
      "source": "categories = train_data[CATEGORIES]\n\nNUM_CATEGORIES = len(categories)\nprint('category count:', NUM_CATEGORIES)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d14164141afed91ff611899627d1c52f0e6fddc5",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# all categories are the same\ntrain_categories = {c[ID]:c[NAME] for c in train_data[CATEGORIES]}\nval_categories = {c[ID]:c[NAME] for c in val_data[CATEGORIES]}\ntest_categories = {c[ID]:c[NAME] for c in test_data[CATEGORIES]}\nassert train_categories == val_categories == test_categories\n\ncategories = train_categories\nprint(categories)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6820463abe2e61a1bc7abf40c74d43b3084e3d63",
        "trusted": true
      },
      "cell_type": "code",
      "source": "IMAGE_PATH = Path(PATH/'JPEGImages/')\nlist(IMAGE_PATH.iterdir())[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "05af92ae8afeae8653c6a3379ffb1a6565f19875"
      },
      "cell_type": "markdown",
      "source": "Helper functions for setting up `pandas.DataFrame` fed to the torch `Dataset`"
    },
    {
      "metadata": {
        "_uuid": "eef14d40a4490e9ae7c13fd04c7fedae26e39736",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_filenames(data):\n    filenames = {o[ID]:o[FILE_NAME] for o in data[IMAGES]}\n    print('get_id_filename_dict')\n    print('length:', len(filenames), 'next item:', next(iter(filenames.items())))\n    return filenames",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7cc5358a8140f7955bf68a8751fbc9a9b137c1b7",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_image_ids(data):\n    image_ids = [o[ID] for o in data[IMAGES]]\n    print('get_image_ids')\n    print('length:', len(image_ids), 'next item:', image_ids[0])\n    return image_ids",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "70e3902fcbc1947d6d8c3afecbaf682395a5a51c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def pascal_bb_hw(bb):\n    return bb[2:]\n\nbbox = train_data[ANNOTATIONS][0][BBOX]\npascal_bb_hw(bbox)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e67e8bf5b70514bae326af9f92ebe99d89addeb5"
      },
      "cell_type": "code",
      "source": "def get_full_filenames(id_filename_dict):\n    # Returns a list of 2 item tuples (image_id, image_full_path)\n    print('get_full_filenames')\n    ret = [(k, f'{IMAGE_PATH}/{v}') for k,v in id_filename_dict.items()]\n    print(preview_data(ret))\n    return ret",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5831057753d8207fe69b73ef87206f5c5f5bbef0"
      },
      "cell_type": "markdown",
      "source": "### Train data structs"
    },
    {
      "metadata": {
        "_uuid": "59c11bcf6e0b6a185f71b7256587e691f9c5ac65",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_filenames = get_filenames(train_data)\ntrain_image_ids = get_image_ids(train_data)\ntrain_full_filenames = get_full_filenames(train_filenames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9ddd49113314835878e40c704c09d60aaef0405e"
      },
      "cell_type": "markdown",
      "source": "### Val data structs"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "feee59024457dc658a23e2249b480507018aa3d7"
      },
      "cell_type": "code",
      "source": "val_filenames = get_filenames(val_data)\nval_image_ids = get_image_ids(val_data)\nval_full_filenames = get_full_filenames(val_filenames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a2ae38466dd8c1829698deab85c83e94b43c7664"
      },
      "cell_type": "code",
      "source": "print(type(train_filenames))\nprint(preview_data(train_filenames))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "caf56a6413da86f51f37752585e24537937ba337"
      },
      "cell_type": "code",
      "source": "print(type(train_image_ids))\nprint(preview_data(train_image_ids))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f8ed156febc4a93a8fc6e9fa3efe974a00acea96"
      },
      "cell_type": "markdown",
      "source": "# Image helper functions"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "edbdf5a25972f8ca58ffef415ce26f59d4680666"
      },
      "cell_type": "code",
      "source": "def show_img(im, figsize=None, ax=None):\n    if not ax:\n        fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    return ax\n\ndef draw_rect(ax, b, edgecolor='white'):\n    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=edgecolor, lw=2))\n    draw_outline(patch, 4)\n    \ndef draw_outline(o, lw):\n    o.set_path_effects([patheffects.Stroke(\n        linewidth=lw, foreground='black'), patheffects.Normal()])\n    \ndef draw_text(ax, xy, txt, sz=14):\n    text = ax.text(*xy, txt,\n        verticalalignment='top', color='white', fontsize=sz, weight='bold')\n    draw_outline(text, 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c467c7c2e7f22a8f1a1f97f2c33e25dc2feb9a3c"
      },
      "cell_type": "markdown",
      "source": "# Multi-box Labels"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc5b89c22987659da68a4a3e4e3cb60d206f60e0"
      },
      "cell_type": "code",
      "source": "preview_data(train_data[ANNOTATIONS])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "929336da060a47f049ca834f4f1d39142efadab9"
      },
      "cell_type": "code",
      "source": "train_ann = collections.defaultdict(lambda:[])\nfor x in train_data[ANNOTATIONS]:\n    train_ann[x[IMAGE_ID]].append((x[BBOX], x[CATEGORY_ID]))\n    \npreview_data(train_ann)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9cce9b49521e898b7cf052f5a1bcb0f0fe57a2b3"
      },
      "cell_type": "code",
      "source": "def get_image_annotations(data):\n    # returns a dict of {image_id: [((bbox, cat), ...)]} \n    # 1 item per image. Can be multi bbox per image\n    ann = collections.defaultdict(lambda:[])\n    for x in data[ANNOTATIONS]:\n        ann[x[IMAGE_ID]].append((x[BBOX], x[CATEGORY_ID]))\n    return ann\n\ntrain_ann = get_image_annotations(train_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ba3f6000281fc731bb632a3410a45c292a054f9"
      },
      "cell_type": "code",
      "source": "preview_data(train_ann)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "939c7a1996e5816ce95a7aa05af4ef83c01be6ce"
      },
      "cell_type": "markdown",
      "source": "### Random image with multi-box labels"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f362699b2fd3c2641bb7273e6304b54975a09f9"
      },
      "cell_type": "code",
      "source": "def show_random_multibox_image(ann, image_ids, filenames):\n    image_id = random.choice(image_ids)\n    im = open_image(str(IMAGE_PATH/filenames[image_id]))\n    ax = show_img(im)\n    for bbox, cat in ann[image_id]:\n        draw_rect(ax, bbox)\n        draw_text(ax, bbox[:2], categories[cat])\n\n# TRAIN dataset example\nshow_random_multibox_image(train_ann, train_image_ids, train_filenames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7d8a0a2703160b99a00032e19ccb3cf6d3414b7e"
      },
      "cell_type": "code",
      "source": "# VAL dataset example\nval_ann = get_image_annotations(val_data)\nshow_random_multibox_image(val_ann, val_image_ids, val_filenames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4b226bf39123f7a2432fc0fccf939369c33e87d7"
      },
      "cell_type": "markdown",
      "source": "Train Examples"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8cc1d868ca68927292c83c4ab2b5a31f2e50d5c8"
      },
      "cell_type": "code",
      "source": "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\nfor i,ax in enumerate(axes.flat):\n    image_id = train_image_ids[i]\n    image_anns = train_ann[image_id]\n    im = open_image(str(IMAGE_PATH/train_filenames[image_id]))\n    ax = show_img(im, ax=ax)\n    for bbox, cat in image_anns:\n        draw_rect(ax, bbox)\n        draw_text(ax, bbox[:2], categories[cat])\nplt.tight_layout()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3878bbee27524f74125e0e92db20d9f8d378df51"
      },
      "cell_type": "markdown",
      "source": "VAL Examples"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e75b9a0f7a8679064777ffc7b97b145115e034d"
      },
      "cell_type": "code",
      "source": "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\nfor i,ax in enumerate(axes.flat):\n    image_id = val_image_ids[i]\n    image_anns = val_ann[image_id]\n    im = open_image(str(IMAGE_PATH/val_filenames[image_id]))\n    ax = show_img(im, ax=ax)\n    for bbox, cat in image_anns:\n        draw_rect(ax, bbox)\n        draw_text(ax, bbox[:2], categories[cat])\nplt.tight_layout()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c0e0f4661b4d83e7b7e1ed0eb8eae9c0f5cb1245"
      },
      "cell_type": "markdown",
      "source": "# 4x4 Grid Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2d694eb407e64b421f7abb7f76f4d80877cc9e06"
      },
      "cell_type": "code",
      "source": "anc_grid = 4\nk = 1\nanc_offset = 1/(anc_grid*2)\nanc_offset",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3df9d0693addd8630da25d1fe98bdf9fe575b665"
      },
      "cell_type": "code",
      "source": "anc_x = np.repeat(np.linspace(anc_offset, 1-anc_offset, anc_grid), 4)\nanc_x",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68cdeca342291d90e497acd39c97a2c266edf1e3"
      },
      "cell_type": "code",
      "source": "anc_y = np.tile(np.linspace(anc_offset, 1-anc_offset, anc_grid), 4)\nanc_y",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55f5cf016cc39c8d5db20c0d038c34f31f0124fb"
      },
      "cell_type": "code",
      "source": "anc_centers = np.tile(np.stack([anc_x,anc_y], axis=1), (k,1))\nanc_centers",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4561303c00d21f4c1db44f001a98e3a7624f6985"
      },
      "cell_type": "code",
      "source": "anc_w = 1/anc_grid\nanc_h = 1/anc_grid\nanc_sizes = np.array([[anc_w, anc_h] for i in range(anc_grid*anc_grid)])\nanc_sizes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4d52b5b4e81bd44054daedb28ba56755b94ba1d"
      },
      "cell_type": "code",
      "source": "np.concatenate([anc_centers, anc_sizes], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5427aeb1448c1b21351efb226967c56473b60cb5"
      },
      "cell_type": "code",
      "source": "anchors = torch.tensor(np.concatenate([anc_centers, anc_sizes], axis=1), requires_grad=False, dtype=torch.float)\nanchors",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "094b24be41894537b1a126f3f61bd8f79aef1d7c"
      },
      "cell_type": "code",
      "source": "grid_sizes = torch.tensor(np.array([1/anc_grid]), requires_grad=False).unsqueeze(1)\ngrid_sizes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5090e012c9a18e1062beebdee9d10267c0749806"
      },
      "cell_type": "code",
      "source": "plt.scatter(anc_x, anc_y)\nplt.xlim(0, 1)\nplt.ylim(0, 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ddec933267421ee1863cec1922e1c52cb199f79"
      },
      "cell_type": "code",
      "source": "anchors",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "963f930f578a6345fee7f470d4f0f8f27ca7e4c1"
      },
      "cell_type": "code",
      "source": "def hw2corners(center, hw):\n    return torch.cat([center-hw/2, center+hw/2], dim=1)\n\nanchor_corners = hw2corners(anchors[:,:2], anchors[:,2:])\nanchor_corners",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "23934d7509d40803b0fb9b58ed3206024c82977c"
      },
      "cell_type": "markdown",
      "source": "Show the above Anchor Boxes data struct"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ac46d1f2b1109eee8fdc21c7e392a29fea7dba6"
      },
      "cell_type": "code",
      "source": "def scale_pascal_bb(bbox, image, size):\n    \"\"\"\n    Returns a bbox scaled to the target `size`\n    \n    Args:\n        bbox (1d array): pascal_bb [x, y, x2, y2]\n        image (3d array): HWC\n        size (scalar): target image size that bbox should be scaled to\n    \"\"\"\n    im_w = image.shape[1]\n    im_h = image.shape[0]\n    return np.multiply(np.divide(bbox, [im_w, im_h, im_w, im_h]), size)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1899ff2f0c16ad92c6f24f70b7e25f0bb4562ee4"
      },
      "cell_type": "code",
      "source": "# image_id = random.choice(train_image_ids)\nimage_id = train_image_ids[1]\nim = open_image(str(IMAGE_PATH/train_filenames[image_id]))\nprint(im.shape)\nresized_image = cv2.resize(im, (SIZE, SIZE)) # HW\nax = show_img(resized_image)\nfor bbox in anchor_corners:\n    draw_rect(ax, bbox*224, edgecolor='red')\nfor bbox, cat in train_ann[image_id]:\n    bbox = scale_pascal_bb(bbox, im, SIZE)\n    draw_rect(ax, bbox)\n    draw_text(ax, bbox[:2], categories[cat])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7bddf90acc87dcefa3a93d4bb3fa93efe27af1f7"
      },
      "cell_type": "markdown",
      "source": "## NEXT: calculate Jaccard overlap per Obj per Anchor Box"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f612fcccce3b2e261cc5751351f3ab3ac816503a"
      },
      "cell_type": "code",
      "source": "actn_bbs = torch.tanh(anchor_corners)\nactn_bbs ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8515e7d53e3093e5f67cb8daa3436cb03457c274"
      },
      "cell_type": "code",
      "source": "actn_centers = (actn_bbs[:,:2]/2 * grid_sizes.float()) + anchors[:,:2]\nactn_centers",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e73c18d04f89164f5cde0978e12de805a9af001"
      },
      "cell_type": "code",
      "source": "actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\nactn_hw",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b079dd46fb109c35f404c690dda610c13edbfdf6"
      },
      "cell_type": "code",
      "source": "hw2corners(actn_centers, actn_hw)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "479b5dd79c84632b13e4f141eac19ce38bd09ff8"
      },
      "cell_type": "code",
      "source": "def actn_to_bb(actn, anchors):\n    actn_bbs = torch.tanh(actn)\n    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes.float()) + anchors[:,:2]\n    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n    return hw2corners(actn_centers, actn_hw)\n\nactn_corners = actn_to_bb(anchor_corners, anchors)\nactn_corners",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b49c5ba1177912952fbd23ef6f06bd6a0c11630d"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f12d200197783ecc8f9151e92e34f641ae0f1ae7"
      },
      "cell_type": "markdown",
      "source": "# Dataset\n\nScales image to (3, 224, 224) for Resnet18\n\nAlso scales the bbox"
    },
    {
      "metadata": {
        "_uuid": "561e962700f7128bc857f7ba7d584e81c1109dc5",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "class BboxDataset(Dataset):\n    def __init__(self, full_filenames, data_ann):\n        \"\"\"\n        Args:\n            full_filenames (list): [(image_id, image_full_path), ...]\n            data_bbox (dict): {image_id: (area, bbox, cat), ...}\n        \"\"\"\n        self.full_filenames = full_filenames\n        self.data_ann = data_ann\n\n    def __len__(self):\n        return len(self.full_filenames)\n    \n    def __getitem__(self, idx):\n        image_id, image_path = self.full_filenames[idx]\n        im = open_image(image_path) # HW\n        resized_image = cv2.resize(im, (SIZE, SIZE)) # HW\n        image = np.transpose(resized_image, (2, 0, 1)) # CHW\n        \n        bbox_cat_list = self.data_ann[image_id]\n        bbox = [bb[0] for bb in bbox_cat_list]\n        cats = [bb[1] for bb in bbox_cat_list]\n        scaled_bbox = scale_pascal_bb(bbox, im, SIZE)        \n\n        return image_id, image, scaled_bbox, cats\n    \ndataset = BboxDataset(train_full_filenames, train_ann)\nidx = 7\nimage_id, inputs, bbox_label, cat_label = dataset[idx]\nimage_id, inputs.shape, bbox_label, cat_label",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b776212196ef71cc3d08aee49f24b612fd5403e7"
      },
      "cell_type": "code",
      "source": "# idx = random.randint(0, 100)\nidx = 7\nimage_id, inputs, bbox_labels, cat_labels = dataset[idx]\nimage_id2, image_path = train_full_filenames[idx]\nassert image_id == image_id2\n\nim = open_image(str(image_path))\nresized_image = cv2.resize(im, (SIZE, SIZE)) # HW\nax = show_img(resized_image)\nfor i in range(len(bbox_labels)):\n    bbox = bbox_labels[i]\n    cat = cat_labels[i]\n    draw_rect(ax, bbox)\n    draw_text(ax, bbox[:2], categories[cat])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7d6b96e0a76b766ce028f566c52f89bedc95e77"
      },
      "cell_type": "markdown",
      "source": "# DataLoader"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a40378aff6017bc1ad503c7ef7cb0fdf3aadae",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "BATCH_SIZE = 2\nNUM_WORKERS = 0\n\ndef collate_fn(mini_batch):\n    mini_batch_count = len(mini_batch)\n    image_ids = torch.tensor([mini_batch[i][0] for i in range(mini_batch_count)])\n    inputs = torch.tensor([mini_batch[i][1] for i in range(mini_batch_count)], dtype=torch.float)\n#     import pdb;pdb.set_trace()\n    bbox_labels = torch.tensor([mini_batch[i][2] for i in range(mini_batch_count)], dtype=torch.float)\n    cat_labels = torch.tensor([mini_batch[i][3] for i in range(mini_batch_count)])\n    return image_ids, inputs, labels\n\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE,\n                        shuffle=True, num_workers=NUM_WORKERS, collate_fn=collate_fn)\n\n# batch_image_ids, batch_inputs, batch_labels = next(iter(dataloader))\nx = next(iter(dataloader))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "15da02fa413f6e5c7b99973681e2baec9a2b9e66"
      },
      "cell_type": "code",
      "source": "image_id, inputs, bbox_labels, cat_labels = x",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "827b4839fd24c12215f836df05782bc42968b3a0"
      },
      "cell_type": "code",
      "source": "image_id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af05606943f49313fd0bce186ba34c0cdaf3eaf9"
      },
      "cell_type": "code",
      "source": "inputs.size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f211951fe4ea2d1e95a85c3a04e8a1a009a56b3"
      },
      "cell_type": "code",
      "source": "bbox_labels.size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac90ea276d3b99b8c31882d1f2f890e5a6741a70"
      },
      "cell_type": "code",
      "source": "cat_label",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9772de88d18124442eca9836d880930e136cdf0"
      },
      "cell_type": "code",
      "source": "len(x[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bdd9f1b82a0f94ecaeb8d9677d9ed0b70cf97a9e"
      },
      "cell_type": "code",
      "source": "image_id, inputs, labels = x[0]\nimage_id, inputs.shape, labels",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0d7f3e5974ed41489dc616ada92519d40587a0b"
      },
      "cell_type": "code",
      "source": "torch.tensor([a[0] for a in x])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0c3f0f38722834bb83e5abb085fa1c3ca534c46"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0f76745c9b00c5054fdd6754726f109faf1e28ca"
      },
      "cell_type": "markdown",
      "source": "### Val Dataset"
    },
    {
      "metadata": {
        "_uuid": "dc912b4bcec1dbf1424ab63854189594e3b8bf9c"
      },
      "cell_type": "markdown",
      "source": "val data structs"
    },
    {
      "metadata": {
        "_uuid": "c53f5ee76947eabdc7376b53a0a6d7537eeb1ce5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "val_filenames = get_filenames(val_data)\nval_image_ids = get_image_ids(val_data)\nval_full_filenames = get_full_filenames(val_filenames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a17ef7d4f46b9768a4864a3ada985ff4e19b298d",
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "val_full_filenames = get_full_filenames(val_filenames)\nnext(iter(val_full_filenames))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb687858584f98a28bf11482faf4f488b94f3b89",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val_image_w_bbox = get_image_w_bbox(val_data, val_image_ids)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3b41d4be4210fecae7ebead7df7438efc04f028f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val_dataset = BboxDataset(val_full_filenames, val_image_w_bbox)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a9dd1514768aabbf4515d4cd96405e42e3902c47",
        "trusted": false
      },
      "cell_type": "code",
      "source": "preview_data(val_filenames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7b2c8e4d3791745a72be5577ed04cf849731c0f9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val_data[ANNOTATIONS][0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f1dc88d77addf4c3076f032ead3a72cae78aaafe",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val_image_w_bbox = get_image_w_bbox(val_data, val_image_ids)\npreview_data(val_image_w_bbox)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0d15a1b2dd68048a004d1cd3f6d942fd9f93d2ea",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(preview_data(val_full_filenames))\nprint(preview_data(val_image_w_bbox))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bd39557992872ee8ea3035474f5a2c6d8c7497bf",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val_dataset = BboxDataset(val_full_filenames, val_image_w_bbox)\nidx = 2\nimage_id, inputs, label = val_dataset[idx]\nimage_id, inputs.shape, label",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "24b5dc5f937f4d6396bb25c4bc89b198ecce6d0d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "label",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "af903fa20f74e76463a802fd2df720e36cea219f"
      },
      "cell_type": "markdown",
      "source": "show Validation dataset image w/ bbox"
    },
    {
      "metadata": {
        "_uuid": "4691d10fcbe3b6d24cf57e38722978133297e293",
        "trusted": false
      },
      "cell_type": "code",
      "source": "show_image_and_bbox(inputs, label)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aee3e2b623064ba3d19d75f9813e901596053c88"
      },
      "cell_type": "markdown",
      "source": "Show the above image at **full scale** for the ground truth to see if it's correct"
    },
    {
      "metadata": {
        "_uuid": "12e82b990f90e3239c78b2db028e18c45bf6ae8b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "idx = 2\nimage_id, filename = val_full_filenames[idx]\nimage_id, filename",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "465bcf05ddb1d524af5723e0226e1478dabb40e0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "area, bbox, cat = val_image_w_bbox[image_id]\narea, bbox, cat",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "08d8fb438ecc856a500a0dfd1d75a49ddc790090",
        "trusted": false
      },
      "cell_type": "code",
      "source": "categories[cat]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "34ecbab2dfac0befcb4c774c4ed2490e0836d539",
        "trusted": false
      },
      "cell_type": "code",
      "source": "im = open_image(filename)\nim.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "6a4fd07ba070bc37ecea90b9a677e89e72b540f4"
      },
      "cell_type": "code",
      "source": "ax = show_img(im)\ndraw_rect(ax, bbox)\ndraw_text(ax, bbox[:2], categories[cat])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa3a4b5613836004a68433f3cce45e615bf012da"
      },
      "cell_type": "markdown",
      "source": "bbox helper functions"
    },
    {
      "metadata": {
        "_uuid": "08656dd9054e753b304690af1727afecf3a1cfd9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def fastai_bb(bb):\n    return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n\nprint(bbox)\nprint(fastai_bb(bbox))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c0452e7a5f625fb0b5947f0fea21cf6ae6e00d19",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def pascal_bb_hw(bb):\n    return bb[2:]\n\nbbox = train_data[ANNOTATIONS][0][BBOX]\npascal_bb_hw(bbox)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d75f6c02fc275340aeaf75465da92ec2f12bca8e"
      },
      "cell_type": "markdown",
      "source": "# DataLoader"
    },
    {
      "metadata": {
        "_uuid": "4832dc8acf67d3a16edaca67aabb76f0f0f5c2cc",
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "BATCH_SIZE = 64\nNUM_WORKERS = 0\n\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE,\n                        shuffle=True, num_workers=NUM_WORKERS)\n\nbatch_image_ids, batch_inputs, batch_labels = next(iter(dataloader))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "269a237e6431a9bcd1ac391c83a2953ffefc16d3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "batch_inputs.size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e2aa3d166a3a3d06428c466eff2eedf87c1addb",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# batch_labels is a list, the first item is the \"batch bbox's\", 2nd item is \"batch categories\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0de314aed0f39af822f66ea0a3a05cb7215ed0f9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "len(batch_labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c95b87fa57f6dc0831ab33902a5902784505a413",
        "trusted": false
      },
      "cell_type": "code",
      "source": "batch_labels[0].size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6d59ba062d102dc9754b657cb27fbbc6e0fb42bc",
        "trusted": false
      },
      "cell_type": "code",
      "source": "batch_labels[1].size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e06eabcf6cfa35b8f19237013159f45b3994b5e7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# train the model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "579d5e724049115b6395bd0f5c86a8ed365c74cb"
      },
      "cell_type": "markdown",
      "source": "Val DataLoader"
    },
    {
      "metadata": {
        "_uuid": "f713e876c4dcf690837fb9d82b23202b6cda01c6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                            shuffle=True, num_workers=NUM_WORKERS)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a7682c44eaa2fcb66e5603fac3a1c80789173e2e"
      },
      "cell_type": "markdown",
      "source": "Device check"
    },
    {
      "metadata": {
        "_uuid": "04203f61bd0e53571a7b6acf41851f25ffd95e3f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print('DEVICE:', device)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0d4ed7656ed6a69d93727b78eefd8a1af868034d"
      },
      "cell_type": "markdown",
      "source": "# Build model"
    },
    {
      "metadata": {
        "_uuid": "8ea2db1005fcf7bfbae40f4b6ee8472f2afa045a",
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model_ft = models.resnet18(pretrained=True)\n\nfor layer in model_ft.parameters():\n    layer.requires_grad = False\n    \nnum_ftrs = model_ft.fc.in_features\nIN_FEATURES = num_ftrs\n\nprint(IN_FEATURES, NUM_CATEGORIES)\n\n# model_ft.fc = nn.Linear(num_ftrs, NUM_CATEGORIES)\n\n# model_ft = model_ft.to(device)\n\n# criterion = nn.CrossEntropyLoss()\n\n# # Observe that all parameters are being optimized\n# optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "28cb7af73532423b1e88b568117ad108339583f1"
      },
      "cell_type": "markdown",
      "source": "# Custom head with single Layer fork to 2 outputs\n\n`[bbox preds, category preds]`"
    },
    {
      "metadata": {
        "_uuid": "e25c083d66ba5205623870b5ba6cacc6d297c370",
        "trusted": false
      },
      "cell_type": "code",
      "source": "class BboxAndCatLayer(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.cat_layer = nn.Linear(IN_FEATURES, NUM_CATEGORIES)\n        self.bbox_layer = nn.Linear(IN_FEATURES, 4)\n        \n    def forward(self, x):\n        return (self.bbox_layer(x), self.cat_layer(x), )\n    \nmodel_ft.fc = BboxAndCatLayer()\n\nmodel_ft = model_ft.to(device)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "50b35aa758a292b9ba9bf0cebd220c50af287c60"
      },
      "cell_type": "markdown",
      "source": "### check Model output dimen"
    },
    {
      "metadata": {
        "_uuid": "fed3fa9c9d9019cbb0fb5fb87f3af2fffcf66a41",
        "trusted": false
      },
      "cell_type": "code",
      "source": "image_ids, inputs, labels = next(iter(dataloader))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7258deb811f6f2e934df84c1c356975ea488e10a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(len(labels))\nprint(type(labels))\nprint(labels[0].size())\nprint(labels[0].dtype)\nprint(labels[1].size())\nprint(labels[1].dtype)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f289d6c9a9b662cbe97c502b397fadeb30e97dbb",
        "trusted": false
      },
      "cell_type": "code",
      "source": "inputs = inputs.to(device)\noutputs = model_ft(inputs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e971cba07d2faff7cb06e8c86d983951bcbb6caf",
        "trusted": false
      },
      "cell_type": "code",
      "source": "bbox_outputs, cat_outputs = outputs\nbbox_outputs.size(), cat_outputs.size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "08b79b88347a9b20066aae86fcf31f49f2d06ec9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "_, cat_preds = torch.max(cat_outputs, dim=1)\ncat_preds.size()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1f3083587a5544c90179874697cb4f8152a1041e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "preds = [bbox_outputs, cat_outputs]\n\nprint(preds[0].size())\nprint(preds[0].dtype)\nprint(preds[1].size())\nprint(preds[1].dtype)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "192761dbd806b976ed73be05f2abdb6a9c591259"
      },
      "cell_type": "markdown",
      "source": "# Loss Function - for custom head"
    },
    {
      "metadata": {
        "_uuid": "a10e894157822eb8b43655c7cfdcb03376e1714b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "class BboxAndCatLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.bbox_loss = nn.L1Loss()\n        self.cat_loss = nn.CrossEntropyLoss()\n        \n    def forward(self, preds, targets):\n        bbox_preds, cat_preds = preds\n        bbox_targets, cat_targets = targets\n\n        # data munging\n        bbox_preds = bbox_preds.to(device, torch.float64)\n        cat_targets_0_indexed = cat_targets - 1\n        \n        # per type of loss\n        bbox_loss = self.bbox_loss(bbox_preds, bbox_targets)\n        cat_loss = self.cat_loss(cat_preds, cat_targets_0_indexed)\n        # cast b/c bbox_loss.dtype == torch.float64\n        cat_loss = cat_loss.to(device, dtype=torch.float64)\n        \n        return bbox_loss + cat_loss\n    \ncriterion = BboxAndCatLoss()\n\npreds = [p.to(device) for p in preds]\nlabels = [x.to(device) for x in labels]\n\nloss = criterion(preds, labels)\nloss",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c93c7ca14ef0121e2fdd0a02eb88d25ff2c616b8"
      },
      "cell_type": "markdown",
      "source": "# Train the model"
    },
    {
      "metadata": {
        "_uuid": "5e12993fb2f17eb2da9dc6c97069b7308db44b89",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Observe that all parameters are being optimized\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bda133df2229ffc261fad8eeee5c58531e502b4a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "TRAIN = 'train'\nVAL = 'val'\n\ndataloaders = {\n    TRAIN: dataloader,\n    VAL: val_dataloader\n}\n\ndataset_sizes = {\n    TRAIN: len(dataset),\n    VAL: len(val_dataset)\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "895ae9b365938e2c9154f367944c9acc865e9df6"
      },
      "cell_type": "code",
      "source": "epoch_losses = {TRAIN: [], VAL: []}\nepoch_accuracies = {TRAIN: [], VAL: []}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "a0580ed97f4b56be19c0277a3c4dbdd8f57597ef"
      },
      "cell_type": "code",
      "source": "best_model_weights = copy.deepcopy(model_ft.state_dict())\nbest_acc = 0.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a03afc1a50a6ca92ed8602552c9e527665e60928",
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# EPOCHS = 1\n\n# for epoch in tqdm(range(EPOCHS)):\n#     print('epoch:', epoch)\n    \n#     for phase in [TRAIN, VAL]:\n#         running_loss = 0.0\n#         running_correct = 0\n\n#         for image_ids, inputs, labels in dataloaders[phase]:\n#             inputs = inputs.to(device)\n\n#             # labels - separate to.(device) b/c labels is a list\n#             (bbox_labels, cat_labels) = labels\n#             bbox_labels = bbox_labels.to(device)\n#             cat_labels = cat_labels.to(device)\n\n#             # clear gradients\n#             optimizer.zero_grad()\n\n#             # forward pass\n#             outputs = model_ft(inputs)\n#             bbox_outputs, cat_outputs = outputs\n#             _, preds = torch.max(cat_outputs, dim=1)\n#             loss = criterion(outputs, (bbox_labels, cat_labels))\n\n#             # backwards pass\n#             if phase == TRAIN:\n#                 loss.backward()\n#                 optimizer.step()\n\n#             running_loss += loss.item() * inputs.size(0)\n#             labels_0_indexed = cat_labels - 1\n#             running_correct += torch.sum(preds == labels_0_indexed)\n\n#         # per epoch/phase\n#         epoch_loss = running_loss / dataset_sizes[phase]\n#         epoch_acc = running_correct.double().item() / dataset_sizes[phase]\n#         epoch_losses[phase].append(epoch_loss)\n#         epoch_accuracies[phase].append(epoch_acc)\n\n#     if epoch_accuracies[VAL][-1] > best_acc:\n#         best_acc = epoch_accuracies[VAL][-1]\n#         best_model_weights = copy.deepcopy(model_ft.state_dict())\n        \n#     print('train loss:', epoch_losses[TRAIN][-1], 'train acc:', epoch_accuracies[TRAIN][-1])\n#     print('val loss:', epoch_losses[VAL][-1], 'val acc:', epoch_accuracies[VAL][-1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f64c8664a6f39865d8d4e5f9ee81131beea09d18"
      },
      "cell_type": "markdown",
      "source": "Graph loss and accuracy"
    },
    {
      "metadata": {
        "_uuid": "180a093a6d69e456d65124a424c0013e3168de24",
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "epoch_losses",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b116d1d203132fa94e75e0fab51e7c0796b45cee",
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "epoch_accuracies",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9003f7eb4ade3aed86de0bff8f72a36333fa9da0"
      },
      "cell_type": "markdown",
      "source": "### check predictions"
    },
    {
      "metadata": {
        "_uuid": "b6f4f8403e5ec7d3caf855a8f59f79ee0a02a9e0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(epoch_losses['train'])\nplt.plot(epoch_losses['val'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e213712dcd365573dd26ac944f3ffeb447c04d64",
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.plot(epoch_accuracies['train'])\nplt.plot(epoch_accuracies['val'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4cd907b9f8e6b4acf46dfbdf4f3d36f8155a39cd"
      },
      "cell_type": "markdown",
      "source": "## save model weights"
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "a6d0e91cdf87023577e164f0d66fda9032b48524"
      },
      "cell_type": "code",
      "source": "MODEL_DIR = Path.cwd()/'data/model'\nprint(MODEL_DIR)\nprint('isdir:', os.path.isdir(MODEL_DIR))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "2565a2cbdd64b91d6758d2aa5ccca5273137214a"
      },
      "cell_type": "code",
      "source": "def maybe_create_model_dir():\n    if not os.path.isdir(MODEL_DIR):\n        os.mkdir(MODEL_DIR)\n\ndef save(state_dict):\n    filepath = f'{MODEL_DIR}/model_{datetime.datetime.now().isoformat()}.pth'\n    torch.save(state_dict, filepath)\n    return filepath\n    \nmaybe_create_model_dir()\n\nfilepath = save(model_ft.state_dict())\nfilepath",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false,
        "_uuid": "e60025609e8a79f6e1ad92fe1697d75b11e9cb3c"
      },
      "cell_type": "code",
      "source": "def load(model, filepath):\n    state_dict = torch.load(filepath)\n    model.load_state_dict(state_dict)\n    return model\n\nmodel = load(model_ft, filepath)\nmodel",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "30acc6e3c5582f2585c93c93549f4a126c728cf4"
      },
      "cell_type": "markdown",
      "source": "## View predictions"
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "a921533060e0b436245d5304dcabbc1bcaa24f57"
      },
      "cell_type": "code",
      "source": "bbox_outputs, cat_outputs = outputs\n_, preds = torch.max(cat_outputs, dim=1)\npreds",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3aa87ca0062b0b105ac03b9f56f37e4e917102a9"
      },
      "cell_type": "markdown",
      "source": "predicted"
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "7fd42aa24509333e70ee7b30f826c1c22cb21aa5"
      },
      "cell_type": "code",
      "source": "preds_count = len(preds)\nfig, axes = plt.subplots(1, 7, figsize=(16, 16))\nfor i, ax in enumerate(axes.flat):\n    im = np.transpose(inputs[i], (1, 2, 0))\n    ax = show_img(im, ax=ax)\n    draw_rect(ax, bbox_outputs[i])\n    draw_text(ax, (0,0), categories[preds[i].item()+1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b37d52000dccb629cb68ada411600e14524b02e1"
      },
      "cell_type": "markdown",
      "source": "Ground truth"
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "9c131fccea2e4994744548d954084638aa0a3b6c"
      },
      "cell_type": "code",
      "source": "preds_count = len(preds)\nfig, axes = plt.subplots(1, 7, figsize=(16, 16))\nfor i, ax in enumerate(axes.flat):\n    im = np.transpose(inputs[i], (1, 2, 0))\n    ax = show_img(im, ax=ax)\n    draw_rect(ax, labels[0][i])\n    draw_text(ax, (0,0), categories[labels[1][i].item()])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "c7b56c52eaaa7e3c98bb39d2c034f381dfb011fc"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}