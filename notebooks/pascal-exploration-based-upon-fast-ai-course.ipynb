{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from fastai.dataset import open_image\n",
    "import json\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "118bf972c981d93118fe3b203b95d9094b85643e"
   },
   "outputs": [],
   "source": [
    "# params\n",
    "SIZE = 224\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "SHOW_IMAGES = False\n",
    "\n",
    "# static\n",
    "IMAGES = 'images'\n",
    "ANNOTATIONS = 'annotations'\n",
    "CATEGORIES = 'categories'\n",
    "ID = 'id'\n",
    "NAME = 'name'\n",
    "IMAGE_ID = 'image_id'\n",
    "BBOX = 'bbox'\n",
    "CATEGORY_ID = 'category_id'\n",
    "FILE_NAME = 'file_name'\n",
    "IMAGE = 'image'\n",
    "CATEGORY = 'category'\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c3cbd58f17c3d2bec6fa63d3466b5174ae36066"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c132fd434c2843a1ad894aa36665272901d74f1"
   },
   "outputs": [],
   "source": [
    "!ls ../input/pascal/pascal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f0c759a56e66938c6739e49811c39275f5e1d3c"
   },
   "outputs": [],
   "source": [
    "PATH = Path('../input/pascal/pascal')\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73c706f2cf75e5859ba28933ca3cb5b6ca21d9a8"
   },
   "outputs": [],
   "source": [
    "train_data = json.load((PATH/'pascal_train2007.json').open())\n",
    "val_data = json.load((PATH/'pascal_val2007.json').open())\n",
    "test_data = json.load((PATH/'pascal_test2007.json').open())\n",
    "\n",
    "print('train:', train_data.keys())\n",
    "print('val:', val_data.keys())\n",
    "print('test:', test_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef583f5efd5e4adf8093ca1f3dcf96febc4a2adf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data[ANNOTATIONS][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a314f39827bd1e068ee355679491feb828137f1"
   },
   "outputs": [],
   "source": [
    "train_data[IMAGES][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4a3cdc3f414c19e16cf66aabdbd43aca7fc3fda"
   },
   "outputs": [],
   "source": [
    "len(train_data[CATEGORIES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f18ad0f37bdc398a5b1c56a7ab8fe8e93dc5393"
   },
   "outputs": [],
   "source": [
    "next(iter(train_data[CATEGORIES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d14164141afed91ff611899627d1c52f0e6fddc5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = {c[ID]:c[NAME] for c in train_data[CATEGORIES]}\n",
    "\n",
    "# all categories are the same\n",
    "val_categories = {c[ID]:c[NAME] for c in val_data[CATEGORIES]}\n",
    "test_categories = {c[ID]:c[NAME] for c in test_data[CATEGORIES]}\n",
    "assert categories == val_categories == test_categories\n",
    "\n",
    "print('category count:', len(categories))\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6820463abe2e61a1bc7abf40c74d43b3084e3d63"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = Path(PATH/'JPEGImages/')\n",
    "list(IMAGE_PATH.iterdir())[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05af92ae8afeae8653c6a3379ffb1a6565f19875"
   },
   "source": [
    "Helper functions for setting up `pandas.DataFrame` fed to the torch `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eef14d40a4490e9ae7c13fd04c7fedae26e39736"
   },
   "outputs": [],
   "source": [
    "def get_filenames(data):\n",
    "    filenames = {o[ID]:o[FILE_NAME] for o in data[IMAGES]}\n",
    "    print('get_id_filename_dict')\n",
    "    print('length:', len(filenames), 'next item:', next(iter(filenames.items())))\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7cc5358a8140f7955bf68a8751fbc9a9b137c1b7"
   },
   "outputs": [],
   "source": [
    "def get_image_ids(data):\n",
    "    image_ids = [o[ID] for o in data[IMAGES]]\n",
    "    print('get_image_ids')\n",
    "    print('length:', len(image_ids), 'next item:', image_ids[0])\n",
    "    return image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70e3902fcbc1947d6d8c3afecbaf682395a5a51c"
   },
   "outputs": [],
   "source": [
    "def pascal_bb_hw(bb):\n",
    "    return bb[2:]\n",
    "\n",
    "bbox = train_data[ANNOTATIONS][0][BBOX]\n",
    "pascal_bb_hw(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aded585d69c9f525c13f1652f12b7c6bc9b3b4af"
   },
   "outputs": [],
   "source": [
    "def get_image_w_area(data, image_ids):\n",
    "    image_w_area = {i:None for i in image_ids}\n",
    "    image_w_area = copy.deepcopy(image_w_area)\n",
    "    for x in data[ANNOTATIONS]:\n",
    "        bbox = x[BBOX]\n",
    "        new_category_id = x[CATEGORY_ID]\n",
    "        image_id = x[IMAGE_ID]\n",
    "        h, w = pascal_bb_hw(bbox)\n",
    "        new_area = h*w\n",
    "        cat_id_area = image_w_area[image_id]\n",
    "        if not cat_id_area:\n",
    "            image_w_area[image_id] = (new_category_id, new_area)\n",
    "        else:\n",
    "            category_id, area = cat_id_area\n",
    "            if new_area > area:\n",
    "                image_w_area[image_id] = (new_category_id, new_area)\n",
    "    print('get_image_w_area')\n",
    "    print('length:', len(image_w_area), 'next item:', next(iter(image_w_area.items())))\n",
    "    return image_w_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5831057753d8207fe69b73ef87206f5c5f5bbef0"
   },
   "source": [
    "train data structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59c11bcf6e0b6a185f71b7256587e691f9c5ac65",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_filenames = get_filenames(train_data)\n",
    "train_image_ids = get_image_ids(train_data)\n",
    "train_image_w_area = get_image_w_area(train_data, train_image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc912b4bcec1dbf1424ab63854189594e3b8bf9c"
   },
   "source": [
    "val data structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c53f5ee76947eabdc7376b53a0a6d7537eeb1ce5"
   },
   "outputs": [],
   "source": [
    "val_filenames = get_filenames(val_data)\n",
    "val_image_ids = get_image_ids(val_data)\n",
    "val_image_w_area = get_image_w_area(val_data, val_image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "563d0ac63abada305b94236220b3fb77293e286e"
   },
   "source": [
    "test data structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32f2a518c4dda03747d4385d468443002a8f4608"
   },
   "outputs": [],
   "source": [
    "test_filenames = get_filenames(test_data)\n",
    "test_image_ids = get_image_ids(test_data)\n",
    "test_image_w_area = get_image_w_area(test_data, test_image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6a8e8168c565a18a814d07f9330c4030f0f83de"
   },
   "source": [
    "train data structs (Legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf9938b6fb1ca4d717531172025ef3068a571e89"
   },
   "outputs": [],
   "source": [
    "train_filenames = {o[ID]:o[FILE_NAME] for o in train_data[IMAGES]}\n",
    "print('length:', len(train_filenames))\n",
    "image1_id, image1_fn = next(iter(train_filenames.items()))\n",
    "image1_id, image1_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c7958c1b7c228d3558308641306516cd4560ab4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_image_ids = [o[ID] for o in train_data[IMAGES]]\n",
    "print('length:', len(train_image_ids))\n",
    "train_image_ids[:BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8a744ba6d5455454d8c0ed5537e868c8f1262b8"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcf7690daaf38bb77739606b77b9f0b0fe291b87"
   },
   "outputs": [],
   "source": [
    "image1_path = IMAGE_PATH/image1_fn\n",
    "image1_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79c3b1f68813ba869ad489c2806bb4dd1f1411d4"
   },
   "outputs": [],
   "source": [
    "str(image1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76de823201eae04a02faf97c98b3084401d4469e"
   },
   "outputs": [],
   "source": [
    "im = open_image(str(IMAGE_PATH/image1_fn))\n",
    "print(type(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d5c0a08b490fb6a5985349972e260f362643bf1"
   },
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f465a259b4afa143f445c89e3c4b80c009c31224"
   },
   "outputs": [],
   "source": [
    "len(train_data[ANNOTATIONS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fd225ea5f55b210b885cfbc549d010ce9a64f2f"
   },
   "outputs": [],
   "source": [
    "# get the biggest object label per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "786f2c45d422151696a9ab2c344cd3b778e8a36c"
   },
   "outputs": [],
   "source": [
    "train_data[ANNOTATIONS][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "098571a72d31ba5b09c0b9edfd858171b1568eb0"
   },
   "outputs": [],
   "source": [
    "bbox = train_data[ANNOTATIONS][0][BBOX]\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08656dd9054e753b304690af1727afecf3a1cfd9"
   },
   "outputs": [],
   "source": [
    "def fastai_bb(bb):\n",
    "    return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n",
    "\n",
    "print(bbox)\n",
    "print(fastai_bb(bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8cdddedeca3f539403aa1e28ebb8b9a81a735e7"
   },
   "outputs": [],
   "source": [
    "fbb = fastai_bb(bbox)\n",
    "fbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ce11890ef052df4eddc2b2ae7c68ffa69151881"
   },
   "outputs": [],
   "source": [
    "def fastai_bb_hw(bb):\n",
    "    h= bb[3]-bb[1]+1\n",
    "    w = bb[2]-bb[0]+1\n",
    "    return [h,w]\n",
    "\n",
    "fastai_bb_hw(fbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0452e7a5f625fb0b5947f0fea21cf6ae6e00d19"
   },
   "outputs": [],
   "source": [
    "def pascal_bb_hw(bb):\n",
    "    return bb[2:]\n",
    "\n",
    "bbox = train_data[ANNOTATIONS][0][BBOX]\n",
    "pascal_bb_hw(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a1a2d7bacfb344c1bf0b458074480a64cb2f343f"
   },
   "source": [
    "show image training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "116b99671bd3cef3900ae72cda80af98172281dd"
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax:\n",
    "        fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c161a064474370841fed827793c2717c33ee7447"
   },
   "outputs": [],
   "source": [
    "def draw_rect(ax, b):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))\n",
    "    draw_outline(patch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "534a61df556b06d86dbf374c762950db3b0ded42"
   },
   "outputs": [],
   "source": [
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30f7096c698701199700f19b27eaab4fc2b779a2"
   },
   "outputs": [],
   "source": [
    "def draw_text(ax, xy, txt, sz=14):\n",
    "    text = ax.text(*xy, txt,\n",
    "        verticalalignment='top', color='white', fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58f8b738c13533067884c56fa48c4a0d5d21430b"
   },
   "outputs": [],
   "source": [
    "ax = show_img(im)\n",
    "image1_ann = train_data[ANNOTATIONS][0]\n",
    "b = image1_ann[BBOX]\n",
    "print(b)\n",
    "draw_rect(ax, b)\n",
    "draw_text(ax, b[:2], categories[image1_ann[CATEGORY_ID]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0092569a6de6405394ae14b01c63ebdf49fc711b"
   },
   "source": [
    "Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db13646d8655ff32ec8ee684fd01fddb3cac5023"
   },
   "outputs": [],
   "source": [
    "# TRAIN - create a Pandas dataframe for: image_id, filename, category\n",
    "train_df = pd.DataFrame({\n",
    "    IMAGE_ID: image_id,\n",
    "    IMAGE: str(IMAGE_PATH/image_fn),\n",
    "    CATEGORY: train_image_w_area[image_id][0]\n",
    "} for image_id, image_fn in train_filenames.items())\n",
    "\n",
    "print('count:', len(train_df))\n",
    "print(train_df.iloc[0])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "602992a1f08bf6c7f81174611f0ca38933f76302"
   },
   "outputs": [],
   "source": [
    "# VAL - create a Pandas dataframe for: image_id, filename, category\n",
    "val_df = pd.DataFrame({\n",
    "    IMAGE_ID: image_id,\n",
    "    IMAGE: str(IMAGE_PATH/image_fn),\n",
    "    CATEGORY: val_image_w_area[image_id][0]\n",
    "} for image_id, image_fn in val_filenames.items())\n",
    "\n",
    "print('count:', len(val_df))\n",
    "print(val_df.iloc[0])\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "066b6c2995117c09300a4621711646c103b20e3c"
   },
   "outputs": [],
   "source": [
    "# NOTE: won't work in Kaggle Kernal b/c read-only file system\n",
    "# BIGGEST_OBJECT_CSV = '../input/pascal/pascal/tmp/biggest-object.csv'\n",
    "# train_df.to_csv(BIGGEST_OBJECT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dbb824dfe1dc1e7e8d2afd9384c1fd75507cffc"
   },
   "source": [
    "subclass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb55adfbedb20416d4f3e07dcfb0536118fb8b07"
   },
   "outputs": [],
   "source": [
    "class BiggestObjectDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im = open_image(self.df.iloc[idx][IMAGE]) # HW\n",
    "        resized_image = cv2.resize(im, (SIZE, SIZE)) # HW\n",
    "        image = np.transpose(resized_image, (2, 0, 1)) # CHW\n",
    "        \n",
    "        category =  self.df.iloc[idx][CATEGORY]\n",
    "\n",
    "        return image, category\n",
    "    \n",
    "dataset = BiggestObjectDataset(train_df)\n",
    "inputs, label = dataset[0]\n",
    "print('label:', label, 'shape:', inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d75f6c02fc275340aeaf75465da92ec2f12bca8e"
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4832dc8acf67d3a16edaca67aabb76f0f0f5c2cc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "batch_inputs, batch_labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "269a237e6431a9bcd1ac391c83a2953ffefc16d3"
   },
   "outputs": [],
   "source": [
    "batch_inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0de314aed0f39af822f66ea0a3a05cb7215ed0f9"
   },
   "outputs": [],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "685a6f09aba7c2d5abb65ee97237066f3bf428e5"
   },
   "outputs": [],
   "source": [
    "val_dataset = BiggestObjectDataset(val_df)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0759e8524b8c8582848bc17a3d0dd7b4519cc303"
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': dataloader,\n",
    "    'val': val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "082a9913acdfe18406863923fa44546420fb3e71"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    'train': len(dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e06eabcf6cfa35b8f19237013159f45b3994b5e7"
   },
   "outputs": [],
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd0f59df9865ed0bb5a58bf904f899f13948662f"
   },
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = len(categories)\n",
    "NUM_CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ea2db1005fcf7bfbae40f4b6ee8472f2afa045a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "for layer in model_ft.parameters():\n",
    "    layer.requires_grad = False\n",
    "    \n",
    "num_ftrs = model_ft.fc.in_features\n",
    "print(num_ftrs, NUM_CATEGORIES)\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, NUM_CATEGORIES)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2c820c1c650e9abcb58a0cebfcdc9037b193132"
   },
   "outputs": [],
   "source": [
    "# epoch - w/ train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a03afc1a50a6ca92ed8602552c9e527665e60928",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print('epoch:', epoch)\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        labels_0_indexed = labels - 1\n",
    "        loss = criterion(outputs, labels_0_indexed)\n",
    "        \n",
    "        # backwards pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_correct += torch.sum(preds == labels_0_indexed)\n",
    "        \n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    epoch_acc = running_correct.double().item() / len(dataset)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epoch_accuracies.append(epoch_acc)\n",
    "    print('loss:', epoch_loss, 'acc:', epoch_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0c384b16ec56e5ef5d55a07f02f7c0afd2969db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epoch - w/ train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a99605c0507caf61edb48ab444eab717a0d46f39",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_loss = {'train': np.inf, 'val': np.inf}\n",
    "epoch_acc = {'train': 0, 'val': 0}\n",
    "\n",
    "epoch_losses = {'train': [], 'val': []}\n",
    "epoch_accuracies = {'train': [], 'val': []}\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print('epoch:', epoch)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model_ft.train()\n",
    "        else:\n",
    "            model_ft.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                # forward pass\n",
    "                outputs = model_ft(inputs)\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                labels_0_indexed = labels - 1\n",
    "                loss = criterion(outputs, labels_0_indexed)\n",
    "\n",
    "                # backwards pass\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_correct += torch.sum(preds == labels_0_indexed)\n",
    "\n",
    "        epoch_acc[phase] = running_correct.double().item() / len(dataset)\n",
    "        epoch_loss[phase] = running_loss / len(dataset)\n",
    "        # running sums\n",
    "        epoch_losses[phase].append(epoch_loss[phase])\n",
    "        epoch_accuracies[phase].append(epoch_acc[phase])\n",
    "    print('phase', phase, 'train loss:', epoch_loss['train'], 'train acc:', epoch_acc['train'], 'val loss:', epoch_loss['val'], 'val acc:', epoch_acc['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f64c8664a6f39865d8d4e5f9ee81131beea09d18"
   },
   "source": [
    "Graph loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "180a093a6d69e456d65124a424c0013e3168de24"
   },
   "outputs": [],
   "source": [
    "epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b116d1d203132fa94e75e0fab51e7c0796b45cee",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9003f7eb4ade3aed86de0bff8f72a36333fa9da0"
   },
   "source": [
    "check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6f4f8403e5ec7d3caf855a8f59f79ee0a02a9e0"
   },
   "outputs": [],
   "source": [
    "plt.plot(epoch_losses['train'])\n",
    "plt.plot(epoch_losses['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e213712dcd365573dd26ac944f3ffeb447c04d64"
   },
   "outputs": [],
   "source": [
    "plt.plot(epoch_accuracies['train'])\n",
    "plt.plot(epoch_accuracies['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d25af2735ed08a7f7c58393ecdc4c46b93b34cf"
   },
   "outputs": [],
   "source": [
    "preds_count = len(preds)\n",
    "fig, axes = plt.subplots(1, preds_count, figsize=(16, 16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    im = np.transpose(inputs[i], (1, 2, 0))\n",
    "    ax = show_img(im, ax=ax)\n",
    "    draw_text(ax, (0,0), categories[preds[i].item()+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42bddd466cfef27b0c74cc8f7bdbe7fe58029c40"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
